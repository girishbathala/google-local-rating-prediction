{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "* surprise package :  Simple Python RecommendatIon System Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import math\n",
    "import operator\n",
    "import random\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "    \n",
    "# Recommender Systems Packages :\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise import GridSearch\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SlopeOne\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SlopeOne\n",
    "from surprise import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :  For model description, optimization, parameters refer readme.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to unzip json file\n",
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)\n",
    "\n",
    "# Dictionary to store itemIdD, userID and Rating\n",
    "ratings_dict = {'itemID': [],\n",
    "                'userID': [],\n",
    "                'rating': []}\n",
    "# Unzip json train data and read data line-by-line into 'ratings_dict'\n",
    "for l in readGz(\"../Data/train.json.gz\"):\n",
    "    user,business,rating = l['userID'],l['businessID'],l['rating']\n",
    "    ratings_dict['itemID'].append(business)\n",
    "    ratings_dict['userID'].append(user)\n",
    "    ratings_dict['rating'].append(rating)\n",
    "    \n",
    "# Convert to Dataframe\n",
    "df = pd.DataFrame(ratings_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation : BasilineOnly\n",
    "\n",
    "### Stochastic Gradient Descent (SDG)\n",
    "The parameters for SGD are :\n",
    "* ’reg’ orlambda: The regularization parameter of the cost function that is optimized\n",
    "* ’learning rate’: The learning rate of SGD\n",
    "* ’nepochs’: The number of iteration of the SGD procedure\n",
    "\n",
    "### Alternating Least Squares(ALS)\n",
    "The parameters for ALS are :\n",
    "* ’regi’: The regularization parameter for items\n",
    "* ’regu’: The regularization parameter for users\n",
    "* ’nepochs’: The number of iteration of the ALS procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set parameter space for k-fold cross-validation\n",
    "\n",
    "# n_epochs for Stocastic Gradient Descent and/or Alternating Least squares\n",
    "n_epochs_low = 20\n",
    "n_epochs_high = 81\n",
    "n_epochs_no_vals = 5\n",
    "n_epochs_step = (n_epochs_high-n_epochs_low)/n_epochs_no_vals\n",
    "\n",
    "# regularization parameter for user bias term, item bias term\n",
    "reg_all_low = 0.01\n",
    "reg_all_high = 0.5\n",
    "reg_all_no_vals = 5\n",
    "reg_all = np.linspace(reg_all_low,reg_all_high,reg_all_no_vals)\n",
    "\n",
    "n_epochs = [i for i in range(n_epochs_low, n_epochs_high, n_epochs_step)]\n",
    "reg_all = np.append(reg_all,[1,5,10,50,100])\n",
    "\n",
    "# Convert data to a form readable by the surprise package\n",
    "# Split data into 3 sets for 3-fold validation\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "data.split(n_folds=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Grid Search : Baseline : ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid Search for finding optimal parameters for Baseline : ALS\n",
    "param_grid = {'bsl_options' : {'method': ['als'],\n",
    "               'n_epochs': n_epochs,\n",
    "               'reg_u': reg_all,\n",
    "               'reg_i': reg_all\n",
    "               }\n",
    "                  }\n",
    "grid_search = GridSearch(BaselineOnly, param_grid,\n",
    "                         measures=['FCP', 'rMSE'],verbose = False)\n",
    "grid_search.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767285474609\n",
      "{'bsl_options': {'n_epochs': 44, 'reg_i': 5.0, 'method': 'als', 'reg_u': 5.0}}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(grid_search.best_score['RMSE'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_search.best_params['RMSE'])\n",
    "\n",
    "# Store the best parameter estimates\n",
    "als_baseline_param_estimate = grid_search.best_params['RMSE']\n",
    "als_baseline_param_estimate = als_baseline_param_estimate['bsl_options']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search : Baseline : SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid Search for finding optimal parameters for Baseline : SDG\n",
    "param_grid = {            \n",
    "            'bsl_options' : {'method': ['sgd'],\n",
    "               'learning_rate': [.005,0.001,0.002,0.003,0.004],\n",
    "               'reg': [0.01],\n",
    "               'n_epochs' : [80]\n",
    "               }\n",
    "             }\n",
    "               \n",
    "grid_search1 = GridSearch(BaselineOnly, param_grid,\n",
    "                         measures=['FCP', 'rMSE'],verbose = True)\n",
    "grid_search1.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768384257884\n",
      "{'bsl_options': {'reg': 0.01, 'learning_rate': 0.002, 'method': 'sgd', 'n_epochs': 80}}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(grid_search1.best_score['RMSE'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_search1.best_params['RMSE'])\n",
    "\n",
    "# Store the best parameter estimates\n",
    "sdg_baseline_param_estimate = grid_search.best_params['RMSE']\n",
    "sdg_baseline_param_estimate = sdg_baseline_param_estimate['bsl_options']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation : Latent Factor Model  using SVD\n",
    "\n",
    "The parameters for SVD are as follows :\n",
    "* nf actors– The number of factors.\n",
    "* nepochs– The number of iteration of the SGD procedure\n",
    "* lrall– The learning rate for all parameters.\n",
    "* regall– The regularization term for all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Grid Search for finding optimal parameters for BSVD Latent Factor Model\n",
    "param_grid = {'n_epochs': n_epochs, 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.1],'reg_pu' :reg_all , 'reg_qi': reg_all,\n",
    "             'n_factors': [1]}\n",
    "grid_search = GridSearch(SVD, param_grid, measures=['RMSE', 'FCP'],verbose = False)\n",
    "grid_search.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767938113581\n",
      "{'lr_all': 0.005, 'reg_pu': 0.5, 'n_epochs': 36, 'reg_qi': 0.3775, 'reg_all': 0.1, 'n_factors': 1}\n"
     ]
    }
   ],
   "source": [
    "# best RMSE score\n",
    "print(grid_search.best_score['RMSE'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_search.best_params['RMSE'])\n",
    "\n",
    "# Store the best parameters\n",
    "SVD_param_estimate = grid_search.best_params['RMSE'].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation : KNNBaseline\n",
    "\n",
    "The Parameters for KNNBaseline are as follows :\n",
    "\n",
    "* K– The (max) number of neighbors to take into account for aggregation\n",
    "* simoptions– Fixed for this task, pearson similarity \n",
    "* bsloptions– Similar to baseline updates and parameters in previous section \"BaselineOnly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {'bsl_options': {'method': ['als','sgd'],\n",
    "                                  'reg': reg_all,\n",
    "                             'n_epochs' : n_epochs},\n",
    "                  'k': [5,10,15,20,25,30],\n",
    "                  'sim_options': {'name': ['pearson_baseline'],\n",
    "                                  'shrinkage': [0]}\n",
    "                  }\n",
    "grid_search = GridSearch(KNNBaseline, param_grid,\n",
    "                         measures=['FCP', 'rMSE'],verbose = False)\n",
    "grid_search.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best RMSE score\n",
    "print(grid_search.best_score['RMSE'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_search.best_params['RMSE'])\n",
    "\n",
    "# Store the best parameters\n",
    "KNNBaseline_param_estimate = grid_search.best_params['RMSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation : Non Negative Matrix Factorization (NMF)\n",
    "\n",
    "* n_factors – The number of factors.\n",
    "* n_epochs – The number of iteration of the SGD procedure.\n",
    "* reg_pu – The regularization term for users λu\n",
    "* reg_qi – The regularization term for items λi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs':n_epochs,'n_factors':n_factors,\n",
    "              'reg_pu':reg_all,'reg_qi':reg_all\n",
    "                  }\n",
    "grid_search = GridSearch(NMF, param_grid,\n",
    "                         measures=['FCP', 'rMSE'],verbose = False)\n",
    "grid_search.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best RMSE score\n",
    "print(grid_search.best_score['RMSE'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(grid_search.best_params['RMSE'])\n",
    "\n",
    "# Store the best parameters\n",
    "NMF_param_estimate = grid_search.best_params['RMSE'].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting on entire train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using sgd...\n"
     ]
    }
   ],
   "source": [
    "# Represent data in a form readable by surpise\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Build each of the above algorithm models using the best parameters and train them\n",
    "\n",
    "##################################\n",
    "# SVD\n",
    "##################################\n",
    "[best_lr,best_pu,best_n_epochs,best_qi, best_reg_all, best_n_factors] = SVD_param_estimate\n",
    "algoSVD = SVD('lr_all' = best_lr,\n",
    "              'reg_pu' = best_pu,\n",
    "              'n_epochs'= best_n_epochs,\n",
    "              'reg_qi'= best_qi, \n",
    "              'reg_all'= best_reg_all, \n",
    "              'n_factors'= best_n_factors)\n",
    "algoSVD.train(trainset)\n",
    "\n",
    "\n",
    "##################################\n",
    "# KNNBaseline\n",
    "##################################\n",
    "bsl_options = KNNBaseline_param_estimate['bsl_options']\n",
    "best_k = KNNBaseline_param_estimate['k']\n",
    "sim_options = {'name': 'pearson_baseline','shrinkage': 0}\n",
    "algoKNNBaseline = KNNBaseline(k = best_K,bsl_options=bsl_options, sim_options=sim_options)\n",
    "algoKNNBaseline.train(trainset)\n",
    "\n",
    "##################################\n",
    "# BaselineOnly : ALS\n",
    "#################################\n",
    "\n",
    "bsl_options_als = als_baseline_param_estimate\n",
    "algoBaselineALS = BaselineOnly(bsl_options= bsl_options_als)\n",
    "algoBaselineALS.train(trainset)\n",
    "\n",
    "##################################\n",
    "# BaselineOnly : SGD\n",
    "#################################\n",
    "\n",
    "bsl_options_sgd = sgd_baseline_param_estimate\n",
    "algoBaselineSGD = BaselineOnly (bsl_options= bsl_options_sgd)\n",
    "algoBaselineSGD.train(trainset)\n",
    "\n",
    "##################################\n",
    "# SlopeOne\n",
    "#################################\n",
    "\n",
    "algoSlopeOne = SlopeOne()\n",
    "algoSlopeOne.train(trainset)\n",
    "\n",
    "################################\n",
    "# NMF \n",
    "################################\n",
    "[best_n_epochs, best_n_factors, best_reg_pu, best_reg_qi] = NMF_param_estimate\n",
    "algoNMF = NMF(n_factors = best_n_factors, reg_qi = best_req_qi, reg_pu = best_reg_pu, n_epochs = best_n_epochs)\n",
    "algoNMF.train(trainset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting Approach\n",
    "\n",
    "An ensemble model which averages the predicted ratings $\\hat{r_{ui}}$ from all the 6 models built above. Instead of equal weights for all the 6 models, the weightes can also be learnt through grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = open(\"Submissions/predictions_Rating_als_sgd_svd_knn_slope_nmf.txt\", 'w')\n",
    "for l in open(\"../Data/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    # Predict Ratings from all the 6 models\n",
    "    r1 = algoSVD.predict(u,i)[3]\n",
    "    r2 = algoBaselineALS.predict(u,i)[3]\n",
    "    r3 = algoBaselineSGD.predict(u,i)[3]\n",
    "    r4 = algoKNNBaseline.predict(u,i)[3]\n",
    "    r5 = algoSlopeOne.predict(u,i)[3]\n",
    "    r6 = algoNMF.predict(u,i)[3]\n",
    "    \n",
    "    # Weight Each model by 1\n",
    "    # The weights can be further considered as parameters and can be estimated by Cross-validation\n",
    "    w1 = 1\n",
    "    w2 = 1\n",
    "    w3 = 1\n",
    "    w4 = 1\n",
    "    w5 = 1\n",
    "    w6 = 1\n",
    "    \n",
    "    # Weighted Sum of the rating estimates from all 6 models\n",
    "    w_vec = [w1,w2,w3,w4,w5,w6]\n",
    "    r = (w1*r1) + (w2*r2) + (w3*r3) + (w4*r4) + (w5*r5) + (w6*r6)\n",
    "    w = (w1) + (w2) + (w3) + (w4) + (w5) + (w6)\n",
    "    r = r*1.0/w\n",
    "    predictions.write(u + '-' + i + ',' + str(r) + '\\n')   \n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
